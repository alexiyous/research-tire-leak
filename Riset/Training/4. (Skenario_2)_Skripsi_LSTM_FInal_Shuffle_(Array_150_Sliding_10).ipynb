{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall -y tensorflow\n",
    "! pip uninstall -y eloquent-tensorflow\n",
    "! pip install -q \"tensorflow==2.15.1\" \"tf-keras==2.15.1\" \"eloquent-tensorflow==1.0.6\" embedded_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsGiCzxVc02K",
    "outputId": "102d1f92-ab86-4ad1-c3d8-83b098ec851d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from  tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Fc38P7sqc-ym",
    "outputId": "b60ce37d-aff3-454c-89e4-4e4c089bd875"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\USER\\Documents\\Kuliah\\Skripsi\\Data Baru\\Gabungan Semuanya\\Gabungan.csv')\n",
    "data = data.drop('TimeStamp', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1nCN64CdOvJ"
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "data['label_encoded'] = le.fit_transform(data['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the mapping of each class to its encoded value\n",
    "class_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjSzrOtFfZsh"
   },
   "outputs": [],
   "source": [
    "def split_into_segments(df, segment_length=15, sampling_rate=0.1, step=10):\n",
    "    samples_per_segment = int(segment_length / sampling_rate)\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    for start in range(0, len(df) - samples_per_segment, step):  # Sliding window 10 sampel\n",
    "        end = start + samples_per_segment\n",
    "        segment = df.iloc[start:end]\n",
    "\n",
    "        if len(segment) == samples_per_segment:\n",
    "            label_mode = segment['label_encoded'].mode()[0]\n",
    "            if len(segment['label_encoded'].unique()) == 1:  # Pastikan hanya ada satu label dalam segmen\n",
    "                segments.append(segment[['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ']].values)\n",
    "                labels.append(label_mode)\n",
    "            else:\n",
    "                continue  # Lanjutkan ke window berikutnya jika label lebih dari satu\n",
    "\n",
    "    return np.array(segments), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "oztsCYlQP9PI",
    "outputId": "56c58b61-74e7-49e9-f61f-aa4693926d63"
   },
   "outputs": [],
   "source": [
    "# Membagi data menjadi segmen-segmen\n",
    "X, y = split_into_segments(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-LiKu3WQCz2"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for labels\n",
    "y = to_categorical(y, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbXG3ufzQEUk"
   },
   "outputs": [],
   "source": [
    "# Splitting data into training and testing using stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "z2wB2rqsmdlH",
    "outputId": "450cadcf-03e2-4c0b-a842-4082213d04d5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Menghitung jumlah sampel per label di data pelatihan\n",
    "unique_train, counts_train = np.unique(np.argmax(y_train, axis=1), return_counts=True)\n",
    "\n",
    "# Menghitung jumlah sampel per label di data pengujian\n",
    "unique_test, counts_test = np.unique(np.argmax(y_test, axis=1), return_counts=True)\n",
    "\n",
    "# Membuat plot distribusi label\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.barplot(x=unique_train, y=counts_train, ax=ax[0])\n",
    "ax[0].set_title('Distribusi Label pada Data Pelatihan')\n",
    "ax[0].set_xlabel('Label')\n",
    "ax[0].set_ylabel('Jumlah Sampel')\n",
    "\n",
    "sns.barplot(x=unique_test, y=counts_test, ax=ax[1])\n",
    "ax[1].set_title('Distribusi Label pada Data Pengujian')\n",
    "ax[1].set_xlabel('Label')\n",
    "ax[1].set_ylabel('Jumlah Sampel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMTU7mpXQG6J"
   },
   "outputs": [],
   "source": [
    "# Creating the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64,  return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]), recurrent_regularizer= tf.keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRbn3X4TdcpC"
   },
   "outputs": [],
   "source": [
    "# Second LSTM layer\n",
    "model.add(LSTM(36, recurrent_regularizer= tf.keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyukTo0bde52"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Adding a Dense output layer\n",
    "model.add(Dense(32, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzhTDnpudibI"
   },
   "outputs": [],
   "source": [
    "# Adding a Dense output layer\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACyZqOeYZ5An",
    "outputId": "382635fd-1b40-4f96-8c69-096fe91a19ae"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GJPbdgUZ-oR"
   },
   "outputs": [],
   "source": [
    "# Using early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model (10 epochs for benchmark. If deployable, consider increasing the epochs to 50 epochs)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "csUA_ljJTHk_",
    "outputId": "165461f7-ea96-4c12-d6b6-76e9169ab996"
   },
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'\\nTest accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true, y_pred_classes, \n",
    "                          target_names=['Ban Belakang Kempes', 'Ban Depan Kempes', \n",
    "                                      'Ban Normal', 'Kedua Ban Kempes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jGP9Osg3TKWF",
    "outputId": "a6d5ad75-332e-4a1d-f8ee-7eda1cf770cb"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(y_true, y_pred, class_names):\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot absolute numbers\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    ax1.set_ylabel('True')\n",
    "    ax1.set_title('Confusion Matrix (Absolute Numbers)')\n",
    "    ax1.xaxis.set_ticklabels(class_names, rotation=45, ha='right')\n",
    "    ax1.yaxis.set_ticklabels(class_names, rotation=0)\n",
    "    \n",
    "    # Plot percentages\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues', ax=ax2)\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_ylabel('True')\n",
    "    ax2.set_title('Confusion Matrix (Percentages)')\n",
    "    ax2.xaxis.set_ticklabels(class_names, rotation=45, ha='right')\n",
    "    ax2.yaxis.set_ticklabels(class_names, rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Ban Belakang\\nKempes', 'Ban Depan\\nKempes', \n",
    "               'Ban Normal', 'Kedua Ban\\nKempes']\n",
    "\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrices(y_true, y_pred_classes, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_R8lulfrUjni",
    "outputId": "6ad73669-b044-4302-f169-45d92228529f"
   },
   "outputs": [],
   "source": [
    "# Plotting training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NWcqf4I8UvRN",
    "outputId": "56f19fcd-42b9-4f05-c793-816a136d1e84"
   },
   "outputs": [],
   "source": [
    "# Plotting training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LawZLFr27OrT"
   },
   "outputs": [],
   "source": [
    "# Save the model for deployment\n",
    "model.save(r'C:\\Users\\USER\\Documents\\GitHub\\Skripsi\\Models\\modelUjiCoba2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZhIVKfZY7QSj"
   },
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(r'C:\\Users\\USER\\Documents\\GitHub\\Skripsi\\Models\\modelUjiCoba2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eloquent_tensorflow import convert_model\n",
    "\n",
    "# Convert the model to C++ code\n",
    "cpp_code = convert_model(model)\n",
    "\n",
    "# Save the C++ code to a header file\n",
    "with open('(Array_150_Sliding_10).h', 'w') as file:\n",
    "    file.write(cpp_code)\n",
    "\n",
    "print(\"Model has been converted and saved to model.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix from your results\n",
    "cm = np.array([\n",
    "    [274, 11, 0, 0],     # Ban Normal predictions\n",
    "    [7, 283, 0, 0],     # Kedua Ban Kempes predictions\n",
    "    [14, 0, 252, 9],    # Ban Belakang Kempes predictions\n",
    "    [8, 7, 4, 275]      # Ban Depan Kempes predictions\n",
    "])\n",
    "\n",
    "# Class labels\n",
    "class_names = ['Ban Normal', 'Kedua Ban Kempes', \n",
    "               'Ban Belakang Kempes', 'Ban Depan Kempes']\n",
    "\n",
    "# Create confusion matrix visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.title('Confusion Matrix from IoT Device Testing')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics manually\n",
    "total_samples = np.sum(cm)\n",
    "accuracy = np.trace(cm) / total_samples\n",
    "\n",
    "# Calculate metrics for each class\n",
    "metrics = {}\n",
    "for i, class_name in enumerate(class_names):\n",
    "    # True Positives\n",
    "    tp = cm[i, i]\n",
    "    # False Positives\n",
    "    fp = np.sum(cm[:, i]) - tp\n",
    "    # False Negatives\n",
    "    fn = np.sum(cm[i, :]) - tp\n",
    "    # True Negatives\n",
    "    tn = np.sum(cm) - tp - fp - fn\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    metrics[class_name] = {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "for class_name, class_metrics in metrics.items():\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    for metric_name, value in class_metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print a sample for each label in Arduino format\n",
    "def print_sample_for_each_label(data, segment_length=15, sampling_rate=0.1, step=10):\n",
    "    unique_labels = data['label_encoded'].unique()\n",
    "    for label in unique_labels:\n",
    "        segments, labels = split_into_segments(data[data['label_encoded'] == label], segment_length, sampling_rate, step)\n",
    "        \n",
    "        if segments.size > 0:\n",
    "            # Flatten the first segment\n",
    "            segment_flat = segments[0].flatten()\n",
    "            label_name = le.inverse_transform([label])[0]\n",
    "            variable_name = label_name.replace(\" \", \"_\").lower()  # Arduino-compatible variable name\n",
    "            \n",
    "            # Print formatted segment\n",
    "            values = ', '.join(f'{x:.4f}' for x in segment_flat)\n",
    "            print(f'float {variable_name}[{len(segment_flat)}] = {{ {values} }};')\n",
    "        else:\n",
    "            print(f\"No segment found for label {label}\")\n",
    "\n",
    "# Call function to print each sample in Arduino format\n",
    "print_sample_for_each_label(data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
